{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a1b75aa0",
      "metadata": {
        "id": "a1b75aa0"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b5d6f54",
      "metadata": {
        "id": "2b5d6f54"
      },
      "source": [
        "File name is represented as \"index of the word\" + \"performer id\" + \"repetition\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import os\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "5OvuSArOLDP0"
      },
      "id": "5OvuSArOLDP0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8450486d",
      "metadata": {
        "id": "8450486d",
        "outputId": "7362e872-ae86-4652-b210-74878e2ba3ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing category: 001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying training videos: 100%|██████████| 12/12 [00:00<00:00, 65.28it/s]\n",
            "Copying testing videos: 100%|██████████| 4/4 [00:00<00:00, 55.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing category: 002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying training videos: 100%|██████████| 12/12 [00:00<00:00, 76.12it/s]\n",
            "Copying testing videos: 100%|██████████| 3/3 [00:00<00:00, 82.92it/s]\n"
          ]
        }
      ],
      "source": [
        "def split_videos_by_category(video_folder, train_folder, test_folder, split_ratio=0.8):\n",
        "    # Creating training and testing folders\n",
        "    os.makedirs(train_folder, exist_ok=True)\n",
        "    os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "    # Grouping videos\n",
        "    category_videos = defaultdict(list)\n",
        "    for video_file in os.listdir(video_folder):\n",
        "        if video_file.endswith('.mp4'):\n",
        "            category = extract_category(video_file)\n",
        "            category_videos[category].append(video_file)\n",
        "\n",
        "    # Videos split - train test\n",
        "    for category, videos in category_videos.items():\n",
        "        num_videos = len(videos)\n",
        "        num_train = int(num_videos * split_ratio)\n",
        "        random.shuffle(videos)\n",
        "\n",
        "        # Videos split - train test\n",
        "        train_videos = videos[:num_train]\n",
        "        test_videos = videos[num_train:]\n",
        "\n",
        "        # Moving files to respective folders\n",
        "        print(f\"Processing category: {category}\")\n",
        "        progress_bar_train = tqdm(total=len(train_videos), desc=\"Copying training videos\")\n",
        "        for video in train_videos:\n",
        "            source_path = os.path.join(video_folder, video)\n",
        "            dest_path = os.path.join(train_folder, video)\n",
        "            shutil.copy(source_path, dest_path)\n",
        "            progress_bar_train.update(1)\n",
        "        progress_bar_train.close()\n",
        "        progress_bar_test = tqdm(total=len(test_videos), desc=\"Copying testing videos\")\n",
        "        for video in test_videos:\n",
        "            source_path = os.path.join(video_folder, video)\n",
        "            dest_path = os.path.join(test_folder, video)\n",
        "            shutil.copy(source_path, dest_path)\n",
        "            progress_bar_test.update(1)\n",
        "        progress_bar_test.close()\n",
        "\n",
        "def extract_category(video_file):\n",
        "    category = video_file.split('_')[0]\n",
        "    return category\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    video_folder = os.getcwd() + \"\\\\gesture_frame\"\n",
        "    train_folder = os.getcwd() + \"\\\\train\"\n",
        "    test_folder = os.getcwd() + \"\\\\test\"\n",
        "\n",
        "    # Split videos into training and testing data by category\n",
        "    split_videos_by_category(video_folder, train_folder, test_folder, split_ratio=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e38dcb3",
      "metadata": {
        "id": "2e38dcb3"
      },
      "source": [
        "# Video to Frame - Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "71d3aa12",
      "metadata": {
        "id": "71d3aa12"
      },
      "outputs": [],
      "source": [
        "# Defining the boundaries for hand segmentation\n",
        "boundaries = [\n",
        "    ([0, 120, 0], [140, 255, 100]),\n",
        "    ([25, 0, 75], [180, 38, 255])\n",
        "]\n",
        "\n",
        "def handsegment(frame):\n",
        "    lower, upper = boundaries[0]\n",
        "    lower = np.array(lower, dtype=\"uint8\")\n",
        "    upper = np.array(upper, dtype=\"uint8\")\n",
        "    mask1 = cv2.inRange(frame, lower, upper)\n",
        "\n",
        "    lower, upper = boundaries[1]\n",
        "    lower = np.array(lower, dtype=\"uint8\")\n",
        "    upper = np.array(upper, dtype=\"uint8\")\n",
        "    mask2 = cv2.inRange(frame, lower, upper)\n",
        "\n",
        "    mask = cv2.bitwise_or(mask1, mask2)\n",
        "    output = cv2.bitwise_and(frame, frame, mask=mask)\n",
        "\n",
        "    return output\n",
        "\n",
        "def convert_video_to_frames(video_path, output_folder, gesture_name, hc, pbar):\n",
        "    # Opening the video file\n",
        "    vidcap = cv2.VideoCapture(video_path)\n",
        "    success, image = vidcap.read()\n",
        "    count = 0\n",
        "    if not success:\n",
        "        print(\"Error: Failed to open video file.\")\n",
        "        return\n",
        "\n",
        "    # Creating a subfolder for each video's frames\n",
        "    video_frame_folder = os.path.join(output_folder, os.path.splitext(os.path.basename(video_path))[0])\n",
        "    os.makedirs(video_frame_folder, exist_ok=True)\n",
        "\n",
        "    # Getting total number of frames in the video\n",
        "    total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    while success:\n",
        "        # saving the grayscale frames\n",
        "        frame_path = os.path.join(video_frame_folder, f\"frame{count}.jpg\")\n",
        "        cv2.imwrite(frame_path, image)\n",
        "\n",
        "        # Append information to list\n",
        "        hc.append({\n",
        "            \"file_path\": frame_path,\n",
        "            \"gesture\": gesture_name,\n",
        "            \"total_frame_count\": count\n",
        "        })\n",
        "        # conducting hand segment\n",
        "        segmented_frame = handsegment(image)\n",
        "        gray_frame = cv2.cvtColor(segmented_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Saving the segmented frame\n",
        "        cv2.imwrite(frame_path, gray_frame)\n",
        "        pbar.update(1)  # Update progress bar\n",
        "        success, image = vidcap.read()\n",
        "        count += 1\n",
        "\n",
        "    # Releasing video capture and destroy all OpenCV windows\n",
        "    vidcap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def extract_category(video_file):\n",
        "    category = video_file.split('_')[0]\n",
        "    return category\n",
        "\n",
        "output_folder = os.path.join(train_folder, \"frames_output\")\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "hc = []\n",
        "\n",
        "pbar_total = len([filename for filename in os.listdir(train_folder) if filename.endswith(\".mp4\")])\n",
        "pbar = tqdm(total=pbar_total, desc=\"Converting frames\")\n",
        "\n",
        "for filename in os.listdir(train_folder):\n",
        "    if filename.endswith(\".mp4\"):\n",
        "        category = extract_category(filename)\n",
        "        category_output_folder = os.path.join(output_folder, category)\n",
        "        os.makedirs(category_output_folder, exist_ok=True)\n",
        "        video_path = os.path.join(train_folder, filename)\n",
        "        convert_video_to_frames(video_path, category_output_folder, category, hc, pbar)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b19fe820",
      "metadata": {
        "id": "b19fe820"
      },
      "source": [
        "# Video to Frame - Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "171eb25d",
      "metadata": {
        "id": "171eb25d"
      },
      "outputs": [],
      "source": [
        "output_folder = os.path.join(test_folder, \"frames_output\")\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "hc = []\n",
        "\n",
        "pbar_total = len([filename for filename in os.listdir(test_folder) if filename.endswith(\".mp4\")])\n",
        "pbar = tqdm(total=pbar_total, desc=\"Converting frames\")\n",
        "\n",
        "for filename in os.listdir(test_folder):\n",
        "    if filename.endswith(\".mp4\"):\n",
        "        category = extract_category(filename)\n",
        "        category_output_folder = os.path.join(output_folder, category)\n",
        "        os.makedirs(category_output_folder, exist_ok=True)\n",
        "        video_path = os.path.join(test_folder, filename)\n",
        "        convert_video_to_frames(video_path, category_output_folder, category, hc, pbar)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02ecfecb",
      "metadata": {
        "id": "02ecfecb"
      },
      "source": [
        "# Hand segment extraction for testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dd0b0e4",
      "metadata": {
        "id": "1dd0b0e4"
      },
      "outputs": [],
      "source": [
        "os.makedirs(test_folder+'\\\\hand_segment_test', exist_ok=True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Updating the path to your colored image\n",
        "    image_path = test_folder+'\\\\frames_output'\n",
        "    output_base_path = test_folder+'\\\\hand_segment_test'\n",
        "\n",
        "    # Iterating over gesture folders\n",
        "    for category_folder in os.listdir(image_path):\n",
        "        for gesture_folder in os.listdir(os.path.join(image_path, category_folder)):\n",
        "            gesture_folder_path = os.path.join(image_path, category_folder, gesture_folder)\n",
        "            if os.path.isdir(gesture_folder_path):  # Checking if it's a directory\n",
        "                # Creating the output folder for the current gesture\n",
        "                output_gesture_folder = os.path.join(output_base_path, category_folder, gesture_folder)\n",
        "                os.makedirs(output_gesture_folder, exist_ok=True)\n",
        "\n",
        "                # Getting list of image files\n",
        "                image_files = os.listdir(gesture_folder_path)\n",
        "                # Setting up progress bar\n",
        "                progress_bar = tqdm(total=len(image_files), desc=f\"Processing {gesture_folder}\")\n",
        "\n",
        "                # Iterating over files in the current gesture folder\n",
        "                for filename in image_files:\n",
        "                    image_file_path = os.path.join(gesture_folder_path, filename)\n",
        "                    # Reading the image\n",
        "                    frame = cv2.imread(image_file_path)\n",
        "\n",
        "                    # Performing hand segmentation\n",
        "                    segmented_image = handsegment(frame)\n",
        "\n",
        "                    # Determining the output file path\n",
        "                    output_file_path = os.path.join(output_gesture_folder, filename)\n",
        "\n",
        "                    # Converting frame to grayscale\n",
        "                    gray_image = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                    # Saving the segmented image\n",
        "                    cv2.imwrite(output_file_path, gray_image)\n",
        "\n",
        "                    # Updating progress bar\n",
        "                    progress_bar.update(1)\n",
        "\n",
        "                # Closing progress bar\n",
        "                progress_bar.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}